{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128b906e-826d-4d47-a09c-fccc0745ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def create_bucket(bucket_name, region=None):\n",
    "    \"\"\"Create an S3 bucket in a specified region\n",
    "\n",
    "    If a region is not specified, the bucket is created in the S3 default\n",
    "    region (us-east-1).\n",
    "\n",
    "    :param bucket_name: Bucket to create\n",
    "    :param region: String region to create bucket in, e.g., 'us-west-2'\n",
    "    :return: True if bucket created, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # Create bucket\n",
    "    try:\n",
    "        if region is None:\n",
    "            s3_client = boto3.client('s3')\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            s3_client = boto3.client('s3', region_name=region)\n",
    "            location = {'LocationConstraint': region}\n",
    "            s3_client.create_bucket(Bucket=bucket_name,\n",
    "                                    CreateBucketConfiguration=location)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def set_bucket_public(bucket_name):\n",
    "    \"\"\"Set the bucket policy to make all objects in the bucket publicly readable\n",
    "\n",
    "    :param bucket_name: Bucket to set the policy on\n",
    "    :return: True if policy was set, else False\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # Define the bucket policy\n",
    "    bucket_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Sid\": \"PublicReadForAllObjects\",\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": \"*\",\n",
    "                \"Action\": \"s3:GetObject\",\n",
    "                \"Resource\": f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Convert the policy from JSON dict to string\n",
    "    bucket_policy = json.dumps(bucket_policy)\n",
    "\n",
    "    # Set the new policy\n",
    "    try:\n",
    "        s3_client.put_bucket_policy(Bucket=bucket_name, Policy=bucket_policy)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def upload_directory(directory_name, bucket, s3_prefix=''):\n",
    "    \"\"\"Upload a directory to an S3 bucket\n",
    "\n",
    "    :param directory_name: Directory to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param s3_prefix: S3 prefix for the uploaded files\n",
    "    :return: True if directory was uploaded, else False\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_name):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            s3_path = os.path.relpath(file_path, directory_name)\n",
    "            if s3_prefix:\n",
    "                s3_path = os.path.join(s3_prefix, s3_path)\n",
    "\n",
    "            try:\n",
    "                s3_client.upload_file(file_path, bucket, s3_path)\n",
    "                print(f'Successfully uploaded {file_path} to s3://{bucket}/{s3_path}')\n",
    "            except ClientError as e:\n",
    "                logging.error(e)\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4254e475-e3b2-4725-a53c-e3ffc2cfb1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing buckets:\n",
      "  das-test-cube\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the list of existing buckets\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Output the bucket names\n",
    "print('Existing buckets:')\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccde91-90f5-42b2-bcc3-957fb5257be0",
   "metadata": {},
   "source": [
    "Right now setting the bucket to public needs to be done manually..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad71d119-57ee-4ea8-9819-974d47914d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An error occurred (AccessDenied) when calling the PutBucketPolicy operation: Access Denied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to set the bucket policy for das-up.\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/.zgroup to s3://das-up/.zgroup\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/.zmetadata to s3://das-up/.zmetadata\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/.zattrs to s3://das-up/.zattrs\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/channel/0 to s3://das-up/channel/0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/channel/.zarray to s3://das-up/channel/.zarray\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/channel/.zattrs to s3://das-up/channel/.zattrs\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/frequency/0 to s3://das-up/frequency/0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/frequency/.zattrs to s3://das-up/frequency/.zattrs\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/frequency/.zarray to s3://das-up/frequency/.zarray\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/time/0 to s3://das-up/time/0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/time/.zarray to s3://das-up/time/.zarray\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/time/.zattrs to s3://das-up/time/.zattrs\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/1.0.0 to s3://das-up/fft/1.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/21.0.0 to s3://das-up/fft/21.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/6.0.0 to s3://das-up/fft/6.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/26.0.0 to s3://das-up/fft/26.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/8.0.0 to s3://das-up/fft/8.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/28.0.0 to s3://das-up/fft/28.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/13.0.0 to s3://das-up/fft/13.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/14.0.0 to s3://das-up/fft/14.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/42.0.0 to s3://das-up/fft/42.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/39.0.0 to s3://das-up/fft/39.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/45.0.0 to s3://das-up/fft/45.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/37.0.0 to s3://das-up/fft/37.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/30.0.0 to s3://das-up/fft/30.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/15.0.0 to s3://das-up/fft/15.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/12.0.0 to s3://das-up/fft/12.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/9.0.0 to s3://das-up/fft/9.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/29.0.0 to s3://das-up/fft/29.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/7.0.0 to s3://das-up/fft/7.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/27.0.0 to s3://das-up/fft/27.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/0.0.0 to s3://das-up/fft/0.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/20.0.0 to s3://das-up/fft/20.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/31.0.0 to s3://das-up/fft/31.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/36.0.0 to s3://das-up/fft/36.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/.zarray to s3://das-up/fft/.zarray\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/38.0.0 to s3://das-up/fft/38.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/44.0.0 to s3://das-up/fft/44.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/43.0.0 to s3://das-up/fft/43.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/.zattrs to s3://das-up/fft/.zattrs\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/35.0.0 to s3://das-up/fft/35.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/49.0.0 to s3://das-up/fft/49.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/32.0.0 to s3://das-up/fft/32.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/40.0.0 to s3://das-up/fft/40.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/47.0.0 to s3://das-up/fft/47.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/11.0.0 to s3://das-up/fft/11.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/16.0.0 to s3://das-up/fft/16.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/18.0.0 to s3://das-up/fft/18.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/3.0.0 to s3://das-up/fft/3.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/23.0.0 to s3://das-up/fft/23.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/4.0.0 to s3://das-up/fft/4.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/24.0.0 to s3://das-up/fft/24.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/46.0.0 to s3://das-up/fft/46.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/41.0.0 to s3://das-up/fft/41.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/33.0.0 to s3://das-up/fft/33.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/34.0.0 to s3://das-up/fft/34.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/48.0.0 to s3://das-up/fft/48.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/5.0.0 to s3://das-up/fft/5.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/25.0.0 to s3://das-up/fft/25.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/2.0.0 to s3://das-up/fft/2.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/22.0.0 to s3://das-up/fft/22.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/19.0.0 to s3://das-up/fft/19.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/17.0.0 to s3://das-up/fft/17.0.0\n",
      "Successfully uploaded /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr/fft/10.0.0 to s3://das-up/fft/10.0.0\n",
      "Successfully uploaded directory /work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr to bucket das-up.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory and bucket\n",
    "cube_dir = \"/work/le837wmue-Rhone-download/cache/cube/DAS_test.zarr\"\n",
    "bucket = \"das-up\"\n",
    "\n",
    "# Create the bucket\n",
    "if create_bucket(bucket, \"eu-north-1\"):\n",
    "    # Set the bucket policy to make it public\n",
    "    if set_bucket_public(bucket):\n",
    "        print(f'Bucket {bucket} is now public.')\n",
    "    else:\n",
    "        print(f'Failed to set the bucket policy for {bucket}.')\n",
    "\n",
    "    # Upload the directory\n",
    "    if upload_directory(cube_dir, bucket):\n",
    "        print(f'Successfully uploaded directory {cube_dir} to bucket {bucket}.')\n",
    "    else:\n",
    "        print(f'Failed to upload directory {cube_dir} to bucket {bucket}.')\n",
    "else:\n",
    "    print(f'Failed to create bucket {bucket}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97137d30-2377-41f1-aa06-d173ad8a284b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing buckets:\n",
      "  das-test-cube\n",
      "  das-up\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()\n",
    "\n",
    "print('Existing buckets:')\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rhoneCube",
   "language": "python",
   "name": "rhonecube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
