{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57160f68-b5c7-45d6-8cc5-6f8503bbf6d2",
   "metadata": {},
   "source": [
    "# Benchmark different file transform approaches\n",
    "\n",
    "This document serves the purpose of improving certain time critical parts of the file creat_cube."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3fa01-d14d-4cf8-829c-aa8e6fb3c197",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Importing the necessary modules (run poetry install to use the environment for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20b242-a79a-4dcf-baaf-33fb45c374c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python basemodules\n",
    "import time\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "\n",
    "# data handling\n",
    "import h5py\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab2777-2e44-43aa-bc85-83bcb0b7e2a0",
   "metadata": {},
   "source": [
    "Reading the folders and filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5a57c1-4c99-46d3-99ae-8db0c29583ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=\"/work/le837wmue-Rhone_download/DAS_2020\"\n",
    "os.chdir(base)\n",
    "folders=os.listdir()\n",
    "#folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6619016f-a7ba-4783-84c2-dcd2e9e92d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in folder 1: 1306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rhone1khz_UTC_20200707_205138.931.h5',\n",
       " 'rhone1khz_UTC_20200707_154908.931.h5',\n",
       " 'rhone1khz_UTC_20200707_164408.931.h5',\n",
       " 'rhone1khz_UTC_20200707_154608.931.h5',\n",
       " 'rhone1khz_UTC_20200707_235338.931.h5',\n",
       " 'rhone1khz_UTC_20200707_135038.931.h5',\n",
       " 'rhone1khz_UTC_20200707_190438.931.h5',\n",
       " 'rhone1khz_UTC_20200707_182508.931.h5',\n",
       " 'rhone1khz_UTC_20200707_183838.931.h5',\n",
       " 'rhone1khz_UTC_20200707_191908.931.h5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(f\"{base}/{folders[0]}\")\n",
    "files=os.listdir()\n",
    "print(\"Number of files in folder 1:\", len(files))\n",
    "files[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057255b-e7a4-461a-b451-75877e18744e",
   "metadata": {},
   "source": [
    "### Benchmarking the file read and conversion to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68941c39-36fb-4fe1-a94d-3e3cbb195a91",
   "metadata": {},
   "source": [
    "1. Using h5py as originally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5eb50e97-a1ca-441b-ab94-ba2059d816a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2979  -4623  -8582 ...   3592   2945   3725]\n",
      " [  7908  -2019  -6477 ...  -2881  -5727    647]\n",
      " [-10515  -3669   2995 ...   2528   1463  -5090]\n",
      " ...\n",
      " [  6664  15762  12302 ...  -4615  -8789  -5392]\n",
      " [   804    389   1578 ...   -908 -12766 -12201]\n",
      " [ -4772 -10940  -1687 ...   5943  -1315  -1256]]\n",
      "Time elapsed: 0.08681368827819824\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "f=h5py.File(files[0],  'r')\n",
    "dset=f['Acoustic']\n",
    "print(np.array(dset))\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c7478-16cc-4094-8b09-83f987aed9b9",
   "metadata": {},
   "source": [
    "2. Using xarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b55ed18-13f7-44fe-809e-cf24172ea637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2979  -4623  -8582 ...   3592   2945   3725]\n",
      " [  7908  -2019  -6477 ...  -2881  -5727    647]\n",
      " [-10515  -3669   2995 ...   2528   1463  -5090]\n",
      " ...\n",
      " [  6664  15762  12302 ...  -4615  -8789  -5392]\n",
      " [   804    389   1578 ...   -908 -12766 -12201]\n",
      " [ -4772 -10940  -1687 ...   5943  -1315  -1256]]\n",
      "Time elapsed: 0.0596165657043457\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "xrH5=xr.open_dataset(files[0], engine='h5netcdf', backend_kwargs={'phony_dims': 'access'}) # we need to pass phony_dims as the file has no xarray readable dimensions\n",
    "print(xrH5[\"Acoustic\"].compute().values)\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61f8d7-31ec-43a2-b0b0-5eac1e7d31c6",
   "metadata": {},
   "source": [
    "Reading a single file, xarray is about 3 hundredths faster than h5py. Let's see if this scales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12cbc7be-0364-4242-88dc-bb0eaa86bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 17.899274826049805\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index,file in enumerate(files[0:40]):\n",
    "    f=h5py.File(files[index],  'r')\n",
    "    dset=f['Acoustic']\n",
    "    np.array(dset)\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399d48f3-594b-48e8-be0a-f978678fa6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 3.1821184158325195\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index,file in enumerate(files[0:40]):\n",
    "    xrH5=xr.open_dataset(files[index], engine='h5netcdf', backend_kwargs={'phony_dims': 'access'})\n",
    "    xrH5[\"Acoustic\"].compute().values\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf2dcb-63e7-462a-9fdf-157819c9be15",
   "metadata": {},
   "source": [
    "It does! Reading 40 files with h5py takes 17.9 seconds, with xarray it takes 2.9 seconds.\n",
    "Can we use multiprocessing to speed up the process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e22dc4e-7002-4fac-b615-2727c2bdb31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count=mp.cpu_count()*2//3 # we tae two thirds so the open file limit is not exceeded\n",
    "cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4749047-9336-4c0f-ae22-535a47e115f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 2.542973756790161\n"
     ]
    }
   ],
   "source": [
    "def read_file(file):\n",
    "    with h5py.File(file, 'r') as f: # we need with so it actually closes\n",
    "        dset = f['Acoustic']\n",
    "        np.array(dset)\n",
    "\n",
    "start=time.time()\n",
    "pool=mp.Pool(cpu_count)\n",
    "pool.map(read_file, files[0:40])\n",
    "pool.close()\n",
    "pool.join()\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "081937d5-848b-48df-bb0a-45ba890fc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.7802202701568604\n"
     ]
    }
   ],
   "source": [
    "def read_file(file):\n",
    "    xrH5=xr.open_dataset(file, engine='h5netcdf', backend_kwargs={'phony_dims': 'access'})\n",
    "    xrH5[\"Acoustic\"].compute().values\n",
    "\n",
    "start=time.time()\n",
    "pool=mp.Pool(cpu_count)\n",
    "pool.map(read_file, files[0:40])\n",
    "pool.close()\n",
    "pool.join()\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1e76a-3776-41ac-90f0-3c6ba15d5697",
   "metadata": {},
   "source": [
    "Xarray with the underlying dask is already using distributed computing. Still, we see that we can improve the reading and conversion to 1.78 seconds. \n",
    "However, h5py's conversion time is also highly reduced to only 2.54 seconds. Let's try it with more files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9fe5a6-8052-487b-b5e4-2857531e8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    with h5py.File(file, 'r') as f: # we need with so it actually closes\n",
    "        dset = f['Acoustic']\n",
    "        np.array(dset)\n",
    "\n",
    "start=time.time()\n",
    "pool=mp.Pool(mp.cpu_count())\n",
    "pool.map(read_file, files[0:200])\n",
    "pool.close()\n",
    "pool.join()\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7deabc6e-765c-4172-ad2e-eaf4d6a979ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 17.176568031311035\n"
     ]
    }
   ],
   "source": [
    "def read_file(file):\n",
    "    xrH5=xr.open_dataset(file, engine='h5netcdf', backend_kwargs={'phony_dims': 'access'})\n",
    "    xrH5[\"Acoustic\"].compute().values\n",
    "\n",
    "start=time.time()\n",
    "pool=mp.Pool(cpu_count)\n",
    "pool.map(read_file, files[0:200])\n",
    "pool.close()\n",
    "pool.join()\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581d56a-4b41-482f-86d3-a5226a87aa1d",
   "metadata": {},
   "source": [
    "As we can see, this scales:\n",
    "200 files with xarray still take only 17.2 seconds, but 200 files with h5py on 85 cpus never finish and the kernel crashes, which might be due to files not being closed properly and using too much memory space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7a58b-77d7-4408-addf-feccd6fdbcf2",
   "metadata": {},
   "source": [
    "### Fourier transfrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aee216-9f2f-4cb1-810e-f69edcb696a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AttributeError##########Base settings#########\n",
    "#granularity of spectrogram\n",
    "d_f = 1 # frequency resolution in Hz\n",
    "d_t = 0.1 # time res in seconds\n",
    "\n",
    "# section\n",
    "loc_a, loc_e = 0, 9200 # cable section to be processed (in meters) - 0==start\n",
    "ind_a, ind_e= loc_a//4, loc_e//4 # channel distances (4m each)\n",
    "nFiles = 5 # number of h5 files processed\n",
    "nCores = 8 # cpu cores\n",
    "\n",
    "\n",
    "day= 22\n",
    "month=7\n",
    "sec=0\n",
    "minut=0\n",
    "hours=0\n",
    "\n",
    "# Additional parameters:\n",
    "file_length = 30 # Length of a single h5 file in seconds.\n",
    "NU = 1000 #Sampling frequency in Hz of the recorded data.\n",
    "freq_max = 100 # maximum frequency cut off value for the analysis\n",
    "seg_length=1/d_f #calculate window length corresponding to d_f\n",
    "N = file_length*NU #number of samples in one file\n",
    "ind_f = int(seg_length*freq_max+1)\n",
    "seg_len=int(seg_length*NU) #how many time points should be in one processing window\n",
    "nseg=int(2*(file_length/seg_length)) #amount of segments for the desired window length\n",
    "location_coords = np.arange(loc_a, loc_e, 4)\n",
    "freq_coords=scipy.fft.rfftfreq(int(NU/d_f), 1/NU)[:ind_f]\n",
    "hop = int(d_t*NU)\n",
    "\n",
    "#fft input arguments\n",
    "args = {\n",
    "    \"ind_f\" : ind_f,\n",
    "    \"ind_a\" : ind_a,\n",
    "    \"ind_e\" : ind_e,\n",
    "    \"seg_len\" : seg_len,\n",
    "    \"hop\" : hop,\n",
    "    \"N\" : N\n",
    "}\n",
    "\n",
    "\n",
    "#path and name of resulting zarr-formatted data cube.\n",
    "ZARR_NAME = \"cryo_cube.zarr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba61694-39c4-40fa-8065-c252e34797af",
   "metadata": {},
   "source": [
    "1. The original approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a374772-3c8a-4d9d-9f45-a4ec39901a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def channel_fourier(data, args, taper, positions):\n",
    "    \"\"\"\n",
    "    Applies Fourier Transformation to segments of DAS records to compute spectrograms.\n",
    "\n",
    "    Args:\n",
    "        data (ndarray): The raw data from DAS channels.\n",
    "        args (dict): Contains parameters for Fourier Transform such as segment length and indices.\n",
    "        taper (ndarray): The taper function to apply before the Fourier transform.\n",
    "        positions (ndarray): The positions of the segments.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: A 3D array containing the Fourier transform for each segment and channel.\n",
    "    \"\"\"\n",
    "    seg_len = args[\"seg_len\"]\n",
    "    ind_e, ind_a = args[\"ind_e\"], args[\"ind_a\"]\n",
    "    ind_f = args[\"ind_f\"]\n",
    "\n",
    "\n",
    "\n",
    "    # data transformation\n",
    "    segs = ([data[pos:pos+seg_len] for pos in positions]) #dividing the data into segments each consisting of desired amount of data points\n",
    "    segs = [seg.T[ind_a:ind_e] for seg in segs] #transposing the segments individually to gain time series for each channel\n",
    "    nseg = positions.shape[0]\n",
    "    \n",
    "    # the first loop iterates over all segments (each corresponding to a time point)\n",
    "    # in the second loop, the fourier transform gets applied on each channel\n",
    "    Fsegs=np.zeros((nseg, ind_e-ind_a, ind_f))\n",
    "    for i in range(nseg):\n",
    "        for channel_number, channel in enumerate(segs[i]):\n",
    "\n",
    "            # note that modified_log(x)=10*log(x) (conversion to\n",
    "\n",
    "            fourier_transformed = np.fft.rfft(taper*channel, n=seg_len)\n",
    "            fourier_transformed = ((10*np.log(np.abs(fourier_transformed)**2)))[0:ind_f]\n",
    "            fourier_transformed[0]=0\n",
    "            Fsegs[i][channel_number]=fourier_transformed\n",
    "\n",
    "    return Fsegs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f=h5py.File(files[0],  'r')\n",
    "dset=f['Acoustic']\n",
    "seg_len=args[\"seg_len\"]\n",
    "hop=args[\"hop\"]\n",
    "N=args[\"N\"]\n",
    "\n",
    "print(np.array(dset))\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rhone",
   "language": "python",
   "name": "rhone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
