{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57160f68-b5c7-45d6-8cc5-6f8503bbf6d2",
   "metadata": {},
   "source": [
    "# Benchmark different file transform approaches\n",
    "\n",
    "This document serves the purpose of improving certain time critical parts of the file creat_cube."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3fa01-d14d-4cf8-829c-aa8e6fb3c197",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Importing the necessary modules (run poetry install to use the environment for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c20b242-a79a-4dcf-baaf-33fb45c374c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python basemodules\n",
    "import time\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "\n",
    "# data handling\n",
    "import h5py\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal, fft\n",
    "import dask.array as da\n",
    "import pyfftw\n",
    "import pyfftw.interfaces.dask_fft as dafft\n",
    "import pickle\n",
    "\n",
    "repo_dir = os.popen('git rev-parse --show-toplevel').read().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab2777-2e44-43aa-bc85-83bcb0b7e2a0",
   "metadata": {},
   "source": [
    "Reading the folders and filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5a57c1-4c99-46d3-99ae-8db0c29583ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=\"/work/le837wmue-Rhone_download/DAS_2020\"\n",
    "os.chdir(base)\n",
    "folders=os.listdir()\n",
    "#folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6619016f-a7ba-4783-84c2-dcd2e9e92d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in folder 1: 1307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rhone1khz_UTC_20200707_205138.931.h5',\n",
       " 'rhone1khz_UTC_20200707_154908.931.h5',\n",
       " 'rhone1khz_UTC_20200707_164408.931.h5',\n",
       " 'rhone1khz_UTC_20200707_154608.931.h5',\n",
       " 'rhone1khz_UTC_20200707_235338.931.h5',\n",
       " 'rhone1khz_UTC_20200707_135038.931.h5',\n",
       " 'rhone1khz_UTC_20200707_190438.931.h5',\n",
       " 'rhone1khz_UTC_20200707_182508.931.h5',\n",
       " 'rhone1khz_UTC_20200707_183838.931.h5',\n",
       " 'rhone1khz_UTC_20200707_191908.931.h5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(f\"{base}/{folders[0]}\")\n",
    "files=os.listdir()\n",
    "print(\"Number of files in folder 1:\", len(files))\n",
    "files[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057255b-e7a4-461a-b451-75877e18744e",
   "metadata": {},
   "source": [
    "### Benchmarking the file read and conversion to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68941c39-36fb-4fe1-a94d-3e3cbb195a91",
   "metadata": {},
   "source": [
    "1. Using h5py as originally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb50e97-a1ca-441b-ab94-ba2059d816a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2979  -4623  -8582 ...   3592   2945   3725]\n",
      " [  7908  -2019  -6477 ...  -2881  -5727    647]\n",
      " [-10515  -3669   2995 ...   2528   1463  -5090]\n",
      " ...\n",
      " [  6664  15762  12302 ...  -4615  -8789  -5392]\n",
      " [   804    389   1578 ...   -908 -12766 -12201]\n",
      " [ -4772 -10940  -1687 ...   5943  -1315  -1256]]\n",
      "Time elapsed: 0.4123396873474121\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "f=h5py.File(files[0],  'r')\n",
    "dset=f['Acoustic']\n",
    "print(np.array(dset))\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c7478-16cc-4094-8b09-83f987aed9b9",
   "metadata": {},
   "source": [
    "2. Using xarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b55ed18-13f7-44fe-809e-cf24172ea637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2979  -4623  -8582 ...   3592   2945   3725]\n",
      " [  7908  -2019  -6477 ...  -2881  -5727    647]\n",
      " [-10515  -3669   2995 ...   2528   1463  -5090]\n",
      " ...\n",
      " [  6664  15762  12302 ...  -4615  -8789  -5392]\n",
      " [   804    389   1578 ...   -908 -12766 -12201]\n",
      " [ -4772 -10940  -1687 ...   5943  -1315  -1256]]\n",
      "Time elapsed: 0.0845937728881836\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "xr_h5=xr.open_dataset(files[0], engine='h5netcdf', backend_kwargs={'phony_dims': 'access'}) # we need to pass phony_dims as the file has no xarray readable dimensions\n",
    "print(xr_h5[\"Acoustic\"].compute().values)\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61f8d7-31ec-43a2-b0b0-5eac1e7d31c6",
   "metadata": {},
   "source": [
    "Reading a single file, xarray is about 3 hundredths faster than h5py. Let's see if this scales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12cbc7be-0364-4242-88dc-bb0eaa86bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 20.112152338027954\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index,file in enumerate(files[0:40]):\n",
    "    f=h5py.File(files[index],  'r')\n",
    "    dset=f['Acoustic']\n",
    "    np.array(dset)\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "399d48f3-594b-48e8-be0a-f978678fa6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 3.881666660308838\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index,file in enumerate(files[0:40]):\n",
    "    xr_h5=xr.open_dataset(files[index], engine='h5netcdf', backend_kwargs={'phony_dims': 'access'})\n",
    "    xr_h5[\"Acoustic\"].compute().values\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf2dcb-63e7-462a-9fdf-157819c9be15",
   "metadata": {},
   "source": [
    "It does! Reading 40 files with h5py takes 17.9 seconds, with xarray it takes 2.9 seconds.\n",
    "Can we use multiprocessing to speed up the process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e22dc4e-7002-4fac-b615-2727c2bdb31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count=mp.cpu_count()*2//3 # we tae two thirds so the open file limit is not exceeded\n",
    "cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4749047-9336-4c0f-ae22-535a47e115f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 3.781881093978882\n"
     ]
    }
   ],
   "source": [
    "def read_file(file):\n",
    "    with h5py.File(file, 'r') as f: # we need with so it actually closes\n",
    "        dset = f['Acoustic']\n",
    "        np.array(dset)\n",
    "\n",
    "start=time.time()\n",
    "pool=mp.Pool(cpu_count)\n",
    "pool.map(read_file, files[0:40])\n",
    "pool.close()\n",
    "pool.join()\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "081937d5-848b-48df-bb0a-45ba890fc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 2.9076411724090576\n"
     ]
    }
   ],
   "source": [
    "def read_file(file):\n",
    "    xr_h5=xr.open_dataset(file, engine='h5netcdf', backend_kwargs={'phony_dims': 'access'})\n",
    "    xr_h5[\"Acoustic\"].compute().values\n",
    "\n",
    "start=time.time()\n",
    "pool=mp.Pool(cpu_count)\n",
    "pool.map(read_file, files[0:40])\n",
    "pool.close()\n",
    "pool.join()\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1e76a-3776-41ac-90f0-3c6ba15d5697",
   "metadata": {},
   "source": [
    "Xarray with the underlying dask is already using distributed computing. Still, we see that we can improve the reading and conversion to 1.78 seconds. \n",
    "However, h5py's conversion time is also highly reduced to only 2.54 seconds. Let's try it with more files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9fe5a6-8052-487b-b5e4-2857531e8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    with h5py.File(file, 'r') as f: # we need with so it actually closes\n",
    "        dset = f['Acoustic']\n",
    "        np.array(dset)\n",
    "\n",
    "start=time.time()\n",
    "pool=mp.Pool(mp.cpu_count())\n",
    "pool.map(read_file, files[0:200])\n",
    "pool.close()\n",
    "pool.join()\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deabc6e-765c-4172-ad2e-eaf4d6a979ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    xr_h5=xr.open_dataset(file, engine='h5netcdf', backend_kwargs={'phony_dims': 'access'})\n",
    "    xr_h5[\"Acoustic\"].compute().values\n",
    "\n",
    "start=time.time()\n",
    "pool=mp.Pool(cpu_count)\n",
    "pool.map(read_file, files[0:200])\n",
    "pool.close()\n",
    "pool.join()\n",
    "end=time.time()\n",
    "print(\"Time elapsed:\", end-start) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581d56a-4b41-482f-86d3-a5226a87aa1d",
   "metadata": {},
   "source": [
    "As we can see, this scales:\n",
    "200 files with xarray still take only 17.2 seconds, but 200 files with h5py on 85 cpus never finish and the kernel crashes, which might be due to files not being closed properly and using too much memory space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7a58b-77d7-4408-addf-feccd6fdbcf2",
   "metadata": {},
   "source": [
    "### Fourier transfrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22aee216-9f2f-4cb1-810e-f69edcb696a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########Base settings#########\n",
    "#granularity of spectrogram\n",
    "d_f = 1 # frequency resolution in Hz\n",
    "d_t = 0.1 # time res in seconds\n",
    "\n",
    "# section\n",
    "loc_a, loc_e = 0, 9200 # cable section to be processed (in meters) - 0==start\n",
    "ind_a, ind_e= loc_a//4, loc_e//4 # channel distances (4m each)\n",
    "nFiles = 5 # number of h5 files processed\n",
    "nCores = 8 # cpu cores\n",
    "\n",
    "\n",
    "day= 22\n",
    "month=7\n",
    "sec=0\n",
    "minut=0\n",
    "hours=0\n",
    "\n",
    "# Additional parameters:\n",
    "file_length = 30 # Length of a single h5 file in seconds.\n",
    "NU = 1000 #Sampling frequency in Hz of the recorded data.\n",
    "freq_max = 100 # maximum frequency cut off value for the analysis\n",
    "seg_length=1/d_f #calculate window length corresponding to d_f\n",
    "N = file_length*NU #number of samples in one file\n",
    "ind_f = int(seg_length*freq_max+1)\n",
    "seg_len=int(seg_length*NU) #how many time points should be in one processing window\n",
    "nseg=int(2*(file_length/seg_length)) #amount of segments for the desired window length\n",
    "location_coords = np.arange(loc_a, loc_e, 4)\n",
    "freq_coords=scipy.fft.rfftfreq(int(NU/d_f), 1/NU)[:ind_f]\n",
    "hop = int(d_t*NU)\n",
    "\n",
    "#fft input arguments\n",
    "args = {\n",
    "    \"ind_f\" : ind_f,\n",
    "    \"ind_a\" : ind_a,\n",
    "    \"ind_e\" : ind_e,\n",
    "    \"seg_len\" : seg_len,\n",
    "    \"hop\" : hop,\n",
    "    \"N\" : N\n",
    "}\n",
    "\n",
    "\n",
    "#path and name of resulting zarr-formatted data cube.\n",
    "ZARR_NAME = \"cryo_cube.zarr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba61694-39c4-40fa-8065-c252e34797af",
   "metadata": {},
   "source": [
    "1. The original approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a374772-3c8a-4d9d-9f45-a4ec39901a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed to concatenate: 0.04962778091430664\n",
      "Time elapsed for numpy fft: 19.632588624954224\n"
     ]
    }
   ],
   "source": [
    "def channel_fourier_numpy(data, args, taper, positions):\n",
    "    \"\"\"\n",
    "    Applies Fourier Transformation to segments of DAS records to compute spectrograms.\n",
    "\n",
    "    Args:\n",
    "        data (ndarray): The raw data from DAS channels.\n",
    "        args (dict): Contains parameters for Fourier Transform such as segment length and indices.\n",
    "        taper (ndarray): The taper function to apply before the Fourier transform.\n",
    "        positions (ndarray): The positions of the segments.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: A 3D array containing the Fourier transform for each segment and channel.\n",
    "    \"\"\"\n",
    "    seg_len = args[\"seg_len\"]\n",
    "    ind_e, ind_a = args[\"ind_e\"], args[\"ind_a\"]\n",
    "    ind_f = args[\"ind_f\"]\n",
    "\n",
    "\n",
    "\n",
    "    # data transformation\n",
    "    segs = ([data[pos:pos+seg_len] for pos in positions]) #dividing the data into segments each consisting of desired amount of data points\n",
    "    segs = [seg.T[ind_a:ind_e] for seg in segs] #transposing the segments individually to gain time series for each channel\n",
    "    nseg = positions.shape[0]\n",
    "    \n",
    "    # the first loop iterates over all segments (each corresponding to a time point)\n",
    "    # in the second loop, the fourier transform gets applied on each channel\n",
    "    Fsegs=np.zeros((nseg, ind_e-ind_a, ind_f))\n",
    "    for i in range(nseg):\n",
    "        for channel_number, channel in enumerate(segs[i]):\n",
    "\n",
    "            # note that modified_log(x)=10*log(x) (conversion to\n",
    "\n",
    "            fourier_transformed = np.fft.rfft(taper*channel, n=seg_len)\n",
    "            fourier_transformed = ((10*np.log(np.abs(fourier_transformed)**2)))[0:ind_f]\n",
    "            fourier_transformed[0]=0\n",
    "            Fsegs[i][channel_number]=fourier_transformed\n",
    "\n",
    "    return Fsegs\n",
    "\n",
    "\n",
    "####### running for only \n",
    "file_index=0\n",
    "f=h5py.File(files[file_index],  'r')\n",
    "dset=f['Acoustic']\n",
    "seg_len=args[\"seg_len\"]\n",
    "hop=args[\"hop\"]\n",
    "N=args[\"N\"]\n",
    "data = np.array(dset) # DAS data\n",
    "taper = signal.windows.tukey(seg_len, 0.25) #taper function - reduce the amplitude of the discontinuities at the boundaries, thereby reducing spectral leakage.\n",
    "\n",
    "\n",
    "# the windowing function (Tukey window in this case) tapers at the ends, \n",
    "#so to avoid losing data at the ends of each file, \n",
    "# the end of one file is overlapped with the beginning of the next file.\n",
    "if file_index!=nFiles-1:\n",
    "\n",
    "    g = h5py.File(files[file_index+1],'r')\n",
    "    dset2=g['Acoustic']\n",
    "    data2= np.array(dset2)\n",
    "    \n",
    "    start=time.time()\n",
    "    data = np.concatenate((data, data2[0:seg_len]), axis=0)\n",
    "    end=time.time()\n",
    "    print(\"Time elapsed to concatenate:\", end-start) \n",
    "\n",
    "j = file_index+1\n",
    "file_pos = file_index * N\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "# If the current file is not the last one\n",
    "if file_index != nFiles-1:\n",
    "    # Calculate the starting positions of each segment in the data\n",
    "    # first segment: (j-1)*N/hop, rounded up\n",
    "    # last segment: (j*N-1)/hop, rounded down\n",
    "    positions = np.arange(np.ceil((j-1)*N/hop), np.floor((j*N-1)/hop)+1, dtype=int)*hop - file_pos # scaled by the hop size and offset by the file position\n",
    "else:\n",
    "    # If last one, start: (j*N-seg_len)/hop\n",
    "    # to ensure that the last segment doesn't extend beyond the end of the data\n",
    "    positions = np.arange(np.ceil((j-1)*N/hop), np.floor((j*N-seg_len)/hop)+1, dtype=int)*hop - file_pos\n",
    "    \n",
    "Fsegs = channel_fourier_numpy(data, args, taper, positions)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Time elapsed for numpy fft:\", end-start) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17b266-08e4-4800-817a-2ea0a2f23195",
   "metadata": {},
   "source": [
    "2. Benchmarking SciPy NumPy pyFFTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d2442fd-f321-46b1-bab9-80c5d3dd7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_fourier(data, args, taper, positions, method='numpy'):\n",
    "    \"\"\"\n",
    "    Applies Fourier Transformation to segments of DAS records using specified method.\n",
    "\n",
    "    Args:\n",
    "        data (ndarray): The raw data from DAS channels.\n",
    "        args (dict): Contains parameters for Fourier Transform such as segment length and indices.\n",
    "        taper (ndarray): The taper function to apply before the Fourier transform.\n",
    "        positions (ndarray): The positions of the segments.\n",
    "        method (str): Method for FFT computation ('numpy', 'scipy', 'pyfftw'). Default is 'numpy'.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: A 3D array containing the Fourier transform for each segment and channel.\n",
    "    \"\"\"\n",
    "    seg_len = args[\"seg_len\"]\n",
    "    ind_e, ind_a = args[\"ind_e\"], args[\"ind_a\"]\n",
    "    ind_f = args[\"ind_f\"]\n",
    "\n",
    "    segs = ([data[pos:pos+seg_len] for pos in positions])\n",
    "    segs = [seg.T[ind_a:ind_e] for seg in segs]\n",
    "\n",
    "    nseg = positions.shape[0]\n",
    "    Fsegs = np.zeros((nseg, ind_e-ind_a, ind_f))\n",
    "\n",
    "    if method == 'numpy':\n",
    "        for i in range(nseg):\n",
    "            for channel_number, channel in enumerate(segs[i]):\n",
    "                fourier_transformed = np.fft.rfft(taper * channel, n=seg_len)\n",
    "                fourier_transformed = ((10 * np.log(np.abs(fourier_transformed) ** 2)))[0:ind_f]\n",
    "                fourier_transformed[0] = 0\n",
    "                Fsegs[i][channel_number] = fourier_transformed\n",
    "\n",
    "    elif method == 'scipy':\n",
    "        for i in range(nseg):\n",
    "            for channel_number, channel in enumerate(segs[i]):\n",
    "                fourier_transformed = fft.fft(taper * channel, n=seg_len)\n",
    "                fourier_transformed = ((10 * np.log(np.abs(fourier_transformed) ** 2)))[0:ind_f]\n",
    "                fourier_transformed[0] = 0\n",
    "                Fsegs[i][channel_number] = fourier_transformed\n",
    "\n",
    "\n",
    "    elif method == 'pyfftw':\n",
    "        \n",
    "        try:\n",
    "            with open(f'{repo_dir}/code/notebooks/fftw_wisdom.pkl', 'rb') as f:\n",
    "                wisdom = pickle.load(f)\n",
    "                pyfftw.import_wisdom(wisdom)\n",
    "                print(\"Found a wisdom file.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"No wisdom file found. Starting without wisdom.\")\n",
    "\n",
    "        # Pre-allocate the input and output arrays for FFTW\n",
    "        fft_input = pyfftw.empty_aligned(seg_len, dtype='complex128')\n",
    "        fft_output = pyfftw.empty_aligned(seg_len, dtype='complex128')\n",
    "\n",
    "        # Create FFTW object\n",
    "        fft_object = pyfftw.FFTW(fft_input, fft_output)\n",
    "\n",
    "        for i in range(nseg):\n",
    "            for channel_number, channel in enumerate(segs[i]):\n",
    "                fft_input[:] = taper * channel  # Apply taper\n",
    "                fft_object()  # Execute FFT\n",
    "                fourier_transformed = ((10 * np.log(np.abs(fft_output) ** 2)))[0:ind_f]\n",
    "                fourier_transformed[0] = 0\n",
    "                Fsegs[i][channel_number] = fourier_transformed\n",
    "\n",
    "        with open(f'{repo_dir}/code/notebooks/fftw_wisdom.pkl', 'wb') as f:\n",
    "            pickle.dump(pyfftw.export_wisdom(), f)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method specified. Choose from 'numpy', 'scipy', or 'pyfftw'.\")\n",
    "\n",
    "    return Fsegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1496762-e052-43e1-82de-7975cb16d3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage for benchmarking\n",
    "file_index = 0\n",
    "seg_len = args[\"seg_len\"]\n",
    "hop = args[\"hop\"]\n",
    "N = args[\"N\"]\n",
    "\n",
    "f = h5py.File(files[file_index], 'r')\n",
    "dset = f['Acoustic']\n",
    "data = np.array(dset)\n",
    "\n",
    "taper = signal.windows.tukey(seg_len, 0.25)\n",
    "\n",
    "if file_index != nFiles - 1:\n",
    "    g = h5py.File(files[file_index + 1], 'r')\n",
    "    dset2 = g['Acoustic']\n",
    "    data2 = np.array(dset2)\n",
    "    data = np.concatenate((data, data2[0:seg_len]), axis=0)\n",
    "\n",
    "j = file_index + 1\n",
    "file_pos = file_index * N\n",
    "\n",
    "if file_index != nFiles - 1:\n",
    "    positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - 1) / hop) + 1, dtype=int) * hop - file_pos\n",
    "else:\n",
    "    positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - seg_len) / hop) + 1, dtype=int) * hop - file_pos\n",
    "\n",
    "# Benchmarking each method\n",
    "methods = ['numpy', 'scipy', 'pyfftw']\n",
    "#methods = ['pyfftw']\n",
    "#methods = ['scipy']\n",
    "# methods = ['numpy']\n",
    "for method in methods:\n",
    "    start = time.time()\n",
    "    Fsegs = channel_fourier(data, args, taper, positions, method=method)\n",
    "    end = time.time()\n",
    "    print(f\"Time elapsed for {method} fft:\", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30f57f31-8777-4b29-9ca6-05dc319d8a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking method: pyfftw\n",
      "No wisdom file found. Starting without wisdom.\n",
      "Time elapsed for pyfftw fft in file 0: 29.353445529937744\n",
      "Found a wisdom file.\n",
      "Time elapsed for pyfftw fft in file 1: 29.174957036972046\n",
      "Found a wisdom file.\n",
      "Time elapsed for pyfftw fft in file 2: 29.14138913154602\n",
      "Found a wisdom file.\n",
      "Time elapsed for pyfftw fft in file 3: 29.096455097198486\n",
      "Found a wisdom file.\n",
      "Time elapsed for pyfftw fft in file 4: 28.372843265533447\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'files' is a list of file paths and 'nFiles' is the total number of files\n",
    "nFiles = 5  # Set this to the actual number of files you want to process\n",
    "#methods = ['numpy', 'scipy', 'pyfftw']  # FFT methods to benchmark\n",
    "methods = ['pyfftw']\n",
    "#methods = ['scipy']\n",
    "# methods = ['numpy']\n",
    "\n",
    "# Loop over each method first\n",
    "for method in methods:\n",
    "    print(f\"Benchmarking method: {method}\")\n",
    "    # Then loop over each file for the current method\n",
    "    for file_index in range(nFiles):\n",
    "        seg_len = args[\"seg_len\"]\n",
    "        hop = args[\"hop\"]\n",
    "        N = args[\"N\"]\n",
    "\n",
    "        f = h5py.File(files[file_index], 'r')\n",
    "        dset = f['Acoustic']\n",
    "        data = np.array(dset)\n",
    "\n",
    "        taper = signal.windows.tukey(seg_len, 0.25)\n",
    "\n",
    "        if file_index != nFiles - 1:\n",
    "            g = h5py.File(files[file_index + 1], 'r')\n",
    "            dset2 = g['Acoustic']\n",
    "            data2 = np.array(dset2)\n",
    "            data = np.concatenate((data, data2[0:seg_len]), axis=0)\n",
    "\n",
    "        j = file_index + 1\n",
    "        file_pos = file_index * N\n",
    "\n",
    "        if file_index != nFiles - 1:\n",
    "            positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - 1) / hop) + 1, dtype=int) * hop - file_pos\n",
    "        else:\n",
    "            positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - seg_len) / hop) + 1, dtype=int) * hop - file_pos\n",
    "\n",
    "        # Benchmark the current method for the current file\n",
    "        start = time.time()\n",
    "        Fsegs = channel_fourier(data, args, taper, positions, method=method)\n",
    "        end = time.time()\n",
    "        print(f\"Time elapsed for {method} fft in file {file_index}:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcca4d3-25af-4f74-b9bd-3e075ff19b22",
   "metadata": {},
   "source": [
    "### Optimizing pyFFTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fa4dcc-fba0-46ee-8c52-99c7bc1854a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_fourier(data, args, taper, positions, method='numpy'):\n",
    "    \"\"\"\n",
    "    Applies Fourier Transformation to segments of DAS records using specified method.\n",
    "\n",
    "    Args:\n",
    "        data (ndarray): The raw data from DAS channels.\n",
    "        args (dict): Contains parameters for Fourier Transform such as segment length and indices.\n",
    "        taper (ndarray): The taper function to apply before the Fourier transform.\n",
    "        positions (ndarray): The positions of the segments.\n",
    "        method (str): Method for FFT computation ('numpy', 'scipy', 'pyfftw'). Default is 'numpy'.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: A 3D array containing the Fourier transform for each segment and channel.\n",
    "    \"\"\"\n",
    "    start=time.time()\n",
    "    seg_len = args[\"seg_len\"]\n",
    "    ind_e, ind_a = args[\"ind_e\"], args[\"ind_a\"]\n",
    "    ind_f = args[\"ind_f\"]\n",
    "\n",
    "    segs = ([data[pos:pos+seg_len] for pos in positions])\n",
    "    segs = [seg.T[ind_a:ind_e] for seg in segs]\n",
    "\n",
    "    nseg = positions.shape[0]\n",
    "    Fsegs = np.zeros((nseg, ind_e-ind_a, ind_f))\n",
    "    step1=time.time()\n",
    "    print(\"Time to create segments: \", step1-start)\n",
    "        \n",
    "    try:\n",
    "        with open(f'{repo_dir}/code/notebooks/fftw_wisdom.pkl', 'rb') as f:\n",
    "            wisdom = pickle.load(f)\n",
    "            pyfftw.import_wisdom(wisdom)\n",
    "            print(\"Found a wisdom file.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No wisdom file found. Starting without wisdom.\")\n",
    "        \n",
    "    step2=time.time()\n",
    "    print(\"Time to load wisdom: \", step2-step1)\n",
    "\n",
    "    # Pre-allocate the input and output arrays for FFTW\n",
    "    fft_input = pyfftw.empty_aligned(seg_len, dtype='complex128')\n",
    "    fft_output = pyfftw.empty_aligned(seg_len, dtype='complex128')\n",
    "\n",
    "    step3=time.time()\n",
    "    print(\"Time to pre-allocate arrays: \", step3-step2)\n",
    "\n",
    "\n",
    "    # Create FFTW object\n",
    "    fft_object = pyfftw.FFTW(fft_input, fft_output, flags=['FFTW_ESTIMATE'], threads=mp.cpu_count()//2)\n",
    "    step4=time.time()\n",
    "    print(\"Time to create FFTW object: \", step4-step3)\n",
    "\n",
    "    for i in range(nseg):\n",
    "        for channel_number, channel in enumerate(segs[i]):\n",
    "            #step5=time.time()\n",
    "            fft_input[:] = taper * channel  # Apply taper\n",
    "            #step6=time.time()\n",
    "            #print(\"Time to apply taper: \", step6-step5)\n",
    "            fft_object()  # Execute FFT\n",
    "            fourier_transformed = ((10 * np.log(np.abs(fft_output) ** 2)))[0:ind_f] # Compute power spectrum\n",
    "            fourier_transformed[0] = 0 # Remove DC component (avarage value of the signal)\n",
    "            Fsegs[i][channel_number] = fourier_transformed\n",
    "\n",
    "    with open(f'{repo_dir}/code/notebooks/fftw_wisdom.pkl', 'wb') as f:\n",
    "        pickle.dump(pyfftw.export_wisdom(), f)\n",
    "\n",
    "\n",
    "    return Fsegs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591cee35-fc55-4b6b-86f5-13ec9826e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking method: pyfftw\n",
      "Time to create segments:  0.00022363662719726562\n",
      "Found a wisdom file.\n",
      "Time to load wisdom:  0.0011110305786132812\n",
      "Time to pre-allocate arrays:  6.127357482910156e-05\n",
      "Time to create FFTW object:  0.00045418739318847656\n",
      "Time elapsed for pyfftw fft in file 0: 29.494694471359253\n",
      "Time to create segments:  0.00021982192993164062\n",
      "Found a wisdom file.\n",
      "Time to load wisdom:  0.0010890960693359375\n",
      "Time to pre-allocate arrays:  4.3392181396484375e-05\n",
      "Time to create FFTW object:  0.00045228004455566406\n",
      "Time elapsed for pyfftw fft in file 1: 28.44540238380432\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'files' is a list of file paths and 'nFiles' is the total number of files\n",
    "nFiles = 2  # Set this to the actual number of files you want to process\n",
    "#methods = ['numpy', 'scipy', 'pyfftw']  # FFT methods to benchmark\n",
    "methods = ['pyfftw']\n",
    "#methods = ['scipy']\n",
    "# methods = ['numpy']\n",
    "\n",
    "# Loop over each method first\n",
    "for method in methods:\n",
    "    print(f\"Benchmarking method: {method}\")\n",
    "    # Then loop over each file for the current method\n",
    "    for file_index in range(nFiles):\n",
    "        seg_len = args[\"seg_len\"]\n",
    "        hop = args[\"hop\"]\n",
    "        N = args[\"N\"]\n",
    "\n",
    "        f = h5py.File(files[file_index], 'r')\n",
    "        dset = f['Acoustic']\n",
    "        data = np.array(dset)\n",
    "\n",
    "        taper = signal.windows.tukey(seg_len, 0.25)\n",
    "\n",
    "        if file_index != nFiles - 1:\n",
    "            g = h5py.File(files[file_index + 1], 'r')\n",
    "            dset2 = g['Acoustic']\n",
    "            data2 = np.array(dset2)\n",
    "            data = np.concatenate((data, data2[0:seg_len]), axis=0)\n",
    "\n",
    "        j = file_index + 1\n",
    "        file_pos = file_index * N\n",
    "\n",
    "        if file_index != nFiles - 1:\n",
    "            positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - 1) / hop) + 1, dtype=int) * hop - file_pos\n",
    "        else:\n",
    "            positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - seg_len) / hop) + 1, dtype=int) * hop - file_pos\n",
    "\n",
    "        # Benchmark the current method for the current file\n",
    "        start = time.time()\n",
    "        Fsegs = channel_fourier(data, args, taper, positions, method=method)\n",
    "        end = time.time()\n",
    "        print(f\"Time elapsed for {method} fft in file {file_index}:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89adcf76-1d03-41c5-98a8-b57bd87a0829",
   "metadata": {},
   "source": [
    "Using rfft from the builders module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ffbf9c-9dee-4f33-b7da-aecef0c05f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_fourier(data, args, taper, positions, method='numpy'):\n",
    "    \"\"\"\n",
    "    Applies Fourier Transformation to segments of DAS records using specified method.\n",
    "\n",
    "    Args:\n",
    "        data (ndarray): The raw data from DAS channels.\n",
    "        args (dict): Contains parameters for Fourier Transform such as segment length and indices.\n",
    "        taper (ndarray): The taper function to apply before the Fourier transform.\n",
    "        positions (ndarray): The positions of the segments.\n",
    "        method (str): Method for FFT computation ('numpy', 'scipy', 'pyfftw'). Default is 'numpy'.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: A 3D array containing the Fourier transform for each segment and channel.\n",
    "    \"\"\"\n",
    "    start=time.time()\n",
    "    seg_len = args[\"seg_len\"]\n",
    "    ind_e, ind_a = args[\"ind_e\"], args[\"ind_a\"]\n",
    "    ind_f = args[\"ind_f\"]\n",
    "\n",
    "    segs = ([data[pos:pos+seg_len] for pos in positions])\n",
    "    segs = [seg.T[ind_a:ind_e] for seg in segs]\n",
    "\n",
    "    nseg = positions.shape[0]\n",
    "    Fsegs = np.zeros((nseg, ind_e-ind_a, ind_f))\n",
    "    step1=time.time()\n",
    "    print(\"Time to create segments: \", step1-start)\n",
    "\n",
    "    # Pre-allocate the input array for FFTW\n",
    "    fft_input = pyfftw.empty_aligned(seg_len, dtype='float64')\n",
    "\n",
    "    # Create FFTW object\n",
    "    fft_object = pyfftw.builders.rfft(fft_input, planner_effort='FFTW_ESTIMATE', threads=mp.cpu_count()//2)\n",
    "\n",
    "    for i in range(nseg):\n",
    "        for channel_number, channel in enumerate(segs[i]):\n",
    "            fft_input[:] = taper * channel  # Apply taper\n",
    "            fft_output = fft_object()  # Execute FFT\n",
    "            fourier_transformed = ((10 * np.log(np.abs(fft_output) ** 2)))[0:ind_f] # Compute power spectrum\n",
    "            fourier_transformed[0] = 0 # Remove DC component (average value of the signal)\n",
    "            Fsegs[i][channel_number] = fourier_transformed\n",
    "\n",
    "    return Fsegs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3191bb4-17ba-4ae3-ac39-ddc144351e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking method: pyfftw\n",
      "Time to create segments:  0.00027251243591308594\n",
      "Time to load wisdom:  9.703636169433594e-05\n",
      "Time elapsed for pyfftw fft in file 0: 18.18965983390808\n",
      "Time to create segments:  0.0002493858337402344\n",
      "Time to load wisdom:  4.76837158203125e-05\n",
      "Time elapsed for pyfftw fft in file 1: 17.55069351196289\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'files' is a list of file paths and 'nFiles' is the total number of files\n",
    "nFiles = 2  # Set this to the actual number of files you want to process\n",
    "#methods = ['numpy', 'scipy', 'pyfftw']  # FFT methods to benchmark\n",
    "methods = ['pyfftw']\n",
    "#methods = ['scipy']\n",
    "# methods = ['numpy']\n",
    "\n",
    "# Loop over each method first\n",
    "for method in methods:\n",
    "    print(f\"Benchmarking method: {method}\")\n",
    "    # Then loop over each file for the current method\n",
    "    for file_index in range(nFiles):\n",
    "        seg_len = args[\"seg_len\"]\n",
    "        hop = args[\"hop\"]\n",
    "        N = args[\"N\"]\n",
    "\n",
    "        f = h5py.File(files[file_index], 'r')\n",
    "        dset = f['Acoustic']\n",
    "        data = np.array(dset)\n",
    "\n",
    "        taper = signal.windows.tukey(seg_len, 0.25)\n",
    "\n",
    "        if file_index != nFiles - 1:\n",
    "            g = h5py.File(files[file_index + 1], 'r')\n",
    "            dset2 = g['Acoustic']\n",
    "            data2 = np.array(dset2)\n",
    "            data = np.concatenate((data, data2[0:seg_len]), axis=0)\n",
    "\n",
    "        j = file_index + 1\n",
    "        file_pos = file_index * N\n",
    "\n",
    "        if file_index != nFiles - 1:\n",
    "            positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - 1) / hop) + 1, dtype=int) * hop - file_pos\n",
    "        else:\n",
    "            positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - seg_len) / hop) + 1, dtype=int) * hop - file_pos\n",
    "\n",
    "        # Benchmark the current method for the current file\n",
    "        start = time.time()\n",
    "        Fsegs = channel_fourier(data, args, taper, positions, method=method)\n",
    "        end = time.time()\n",
    "        print(f\"Time elapsed for {method} fft in file {file_index}:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36311b5f-e33d-4054-bd60-7261e219e9a9",
   "metadata": {},
   "source": [
    "Using dask rfft instead of the direct FFTW object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81deecc6-3b2b-4334-8dd4-ea7cc8a4a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_fourier(data, args, taper, positions, method='numpy'):\n",
    "    \n",
    "    # Enable the pyfftw cache\n",
    "    pyfftw.interfaces.cache.enable()\n",
    "    start=time.time()\n",
    "    seg_len = args[\"seg_len\"]\n",
    "    ind_e, ind_a = args[\"ind_e\"], args[\"ind_a\"]\n",
    "    ind_f = args[\"ind_f\"]\n",
    "\n",
    "    segs = ([data[pos:pos+seg_len] for pos in positions])\n",
    "    segs = [seg.T[ind_a:ind_e] for seg in segs]\n",
    "\n",
    "    nseg = positions.shape[0]\n",
    "    Fsegs = np.zeros((nseg, ind_e-ind_a, ind_f))\n",
    "    step1=time.time()\n",
    "    print(\"Time to create segments: \", step1-start)\n",
    "        \n",
    "    try:\n",
    "        with open(f'{repo_dir}/code/notebooks/fftw_wisdom.pkl', 'rb') as f:\n",
    "            wisdom = pickle.load(f)\n",
    "            pyfftw.import_wisdom(wisdom)\n",
    "            print(\"Found a wisdom file.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No wisdom file found. Starting without wisdom.\")\n",
    "        \n",
    "    step2=time.time()\n",
    "    print(\"Time to load wisdom: \", step2-step1)\n",
    "\n",
    "    for i in range(nseg):\n",
    "        for channel_number, channel in enumerate(segs[i]):\n",
    "            # Convert the channel data to a Dask array\n",
    "            channel_da = da.from_array(channel, chunks=seg_len)\n",
    "            \n",
    "            # Apply taper and compute FFT using pyFFTW\n",
    "            fft_output = dafft.rfft(taper * channel_da)\n",
    "            \n",
    "            # Compute the result\n",
    "            fourier_transformed = ((10 * np.log(np.abs(fft_output.compute()) ** 2)))[0:ind_f]\n",
    "            fourier_transformed[0] = 0\n",
    "            Fsegs[i][channel_number] = fourier_transformed\n",
    "\n",
    "    with open(f'{repo_dir}/code/notebooks/fftw_wisdom.pkl', 'wb') as f:\n",
    "        pickle.dump(pyfftw.export_wisdom(), f)\n",
    "\n",
    "    return Fsegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f3330-922e-4392-b6e1-e0785635c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'files' is a list of file paths and 'nFiles' is the total number of files\n",
    "nFiles = 2  # Set this to the actual number of files you want to process\n",
    "#methods = ['numpy', 'scipy', 'pyfftw']  # FFT methods to benchmark\n",
    "methods = ['pyfftw']\n",
    "#methods = ['scipy']\n",
    "# methods = ['numpy']\n",
    "\n",
    "# Loop over each method first\n",
    "for method in methods:\n",
    "    print(f\"Benchmarking method: {method}\")\n",
    "    # Then loop over each file for the current method\n",
    "    for file_index in range(nFiles):\n",
    "        seg_len = args[\"seg_len\"]\n",
    "        hop = args[\"hop\"]\n",
    "        N = args[\"N\"]\n",
    "\n",
    "        f = h5py.File(files[file_index], 'r')\n",
    "        dset = f['Acoustic']\n",
    "        data = np.array(dset)\n",
    "\n",
    "        taper = signal.windows.tukey(seg_len, 0.25)\n",
    "\n",
    "        if file_index != nFiles - 1:\n",
    "            g = h5py.File(files[file_index + 1], 'r')\n",
    "            dset2 = g['Acoustic']\n",
    "            data2 = np.array(dset2)\n",
    "            data = np.concatenate((data, data2[0:seg_len]), axis=0)\n",
    "\n",
    "        j = file_index + 1\n",
    "        file_pos = file_index * N\n",
    "\n",
    "        if file_index != nFiles - 1:\n",
    "            positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - 1) / hop) + 1, dtype=int) * hop - file_pos\n",
    "        else:\n",
    "            positions = np.arange(np.ceil((j - 1) * N / hop), np.floor((j * N - seg_len) / hop) + 1, dtype=int) * hop - file_pos\n",
    "\n",
    "        # Benchmark the current method for the current file\n",
    "        start = time.time()\n",
    "        Fsegs = channel_fourier(data, args, taper, positions, method=method)\n",
    "        end = time.time()\n",
    "        print(f\"Time elapsed for {method} fft in file {file_index}:\", end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data-praktikum",
   "language": "python",
   "name": "rhone-eojzauou-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
