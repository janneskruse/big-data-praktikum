Number of folders before moving files: 34
Number of folders after moving files: 34
Processing folder 20200705
********************
Max number of CPUs:  128
Processed day: 05.07.2020
Time resolution: 0.1 sec
Frequency resolution: 1 Hz
Resulting overlap: 0.9
**********
Creating zarr shape...
Creating metadata...
/home/sc.uni-leipzig.de/ju554xqou/big-data-praktikum/code/slurm/02_fft_pipeline.py:465: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future
  start_time = np.datetime64(attr["ISO8601 Timestamp"]) # Convert to numpy datetime64[ns]
/home/sc.uni-leipzig.de/ju554xqou/big-data-praktikum/code/slurm/02_fft_pipeline.py:469: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.
  xr_zarr = xr.Dataset(
metadata created in 0.12740159034729004s:
Creating and writing empty /work/ju554xqou-rhonezarrs/cryo_cube20200705.zarr with metadata...
zarr created in 738.83713722229s
Memory per file (MB): 113.60244750976562
Number of cores used: 115
Starting FFT for split_up liste [   0    1    2 ... 2470 2471 2472]
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/software/all/Anaconda3/2021.11/lib/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/software/all/Anaconda3/2021.11/lib/python3.9/multiprocessing/pool.py", line 51, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
  File "/home/sc.uni-leipzig.de/ju554xqou/big-data-praktikum/code/slurm/02_fft_pipeline.py", line 239, in create_spectro_segment
    n_files=args["n_files"]
KeyError: 'n_files'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/sc.uni-leipzig.de/ju554xqou/big-data-praktikum/code/slurm/02_fft_pipeline.py", line 526, in <module>
    pool=mp.Pool(n_cores)
  File "/software/all/Anaconda3/2021.11/lib/python3.9/multiprocessing/pool.py", line 372, in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
  File "/software/all/Anaconda3/2021.11/lib/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
KeyError: 'n_files'
